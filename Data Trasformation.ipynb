{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10158460",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING AND FEATURE ENGINEERING IN MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d9c9d",
   "metadata": {},
   "source": [
    "# Data Loading & Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce25b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   age          workclass  fnlwgt   education  education_num  \\\n",
      "0   39          State-gov   77516   Bachelors             13   \n",
      "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38            Private  215646     HS-grad              9   \n",
      "3   53            Private  234721        11th              7   \n",
      "4   28            Private  338409   Bachelors             13   \n",
      "\n",
      "        marital_status          occupation    relationship    race      sex  \\\n",
      "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
      "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
      "0          2174             0              40   United-States   <=50K  \n",
      "1             0             0              13   United-States   <=50K  \n",
      "2             0             0              40   United-States   <=50K  \n",
      "3             0             0              40   United-States   <=50K  \n",
      "4             0             0              40            Cuba   <=50K  \n",
      "\n",
      "Summary statistics:\n",
      "                 age workclass        fnlwgt education  education_num  \\\n",
      "count   32561.000000     32561  3.256100e+04     32561   32561.000000   \n",
      "unique           NaN         9           NaN        16            NaN   \n",
      "top              NaN   Private           NaN   HS-grad            NaN   \n",
      "freq             NaN     22696           NaN     10501            NaN   \n",
      "mean       38.581647       NaN  1.897784e+05       NaN      10.080679   \n",
      "std        13.640433       NaN  1.055500e+05       NaN       2.572720   \n",
      "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
      "25%        28.000000       NaN  1.178270e+05       NaN       9.000000   \n",
      "50%        37.000000       NaN  1.783560e+05       NaN      10.000000   \n",
      "75%        48.000000       NaN  2.370510e+05       NaN      12.000000   \n",
      "max        90.000000       NaN  1.484705e+06       NaN      16.000000   \n",
      "\n",
      "             marital_status       occupation relationship    race    sex  \\\n",
      "count                 32561            32561        32561   32561  32561   \n",
      "unique                    7               15            6       5      2   \n",
      "top      Married-civ-spouse   Prof-specialty      Husband   White   Male   \n",
      "freq                  14976             4140        13193   27816  21790   \n",
      "mean                    NaN              NaN          NaN     NaN    NaN   \n",
      "std                     NaN              NaN          NaN     NaN    NaN   \n",
      "min                     NaN              NaN          NaN     NaN    NaN   \n",
      "25%                     NaN              NaN          NaN     NaN    NaN   \n",
      "50%                     NaN              NaN          NaN     NaN    NaN   \n",
      "75%                     NaN              NaN          NaN     NaN    NaN   \n",
      "max                     NaN              NaN          NaN     NaN    NaN   \n",
      "\n",
      "        capital_gain  capital_loss  hours_per_week  native_country  income  \n",
      "count   32561.000000  32561.000000    32561.000000           32561   32561  \n",
      "unique           NaN           NaN             NaN              42       2  \n",
      "top              NaN           NaN             NaN   United-States   <=50K  \n",
      "freq             NaN           NaN             NaN           29170   24720  \n",
      "mean     1077.648844     87.303830       40.437456             NaN     NaN  \n",
      "std      7385.292085    402.960219       12.347429             NaN     NaN  \n",
      "min         0.000000      0.000000        1.000000             NaN     NaN  \n",
      "25%         0.000000      0.000000       40.000000             NaN     NaN  \n",
      "50%         0.000000      0.000000       40.000000             NaN     NaN  \n",
      "75%         0.000000      0.000000       45.000000             NaN     NaN  \n",
      "max     99999.000000   4356.000000       99.000000             NaN     NaN  \n",
      "\n",
      "Missing values by column:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "age                int64\n",
      "workclass         object\n",
      "fnlwgt             int64\n",
      "education         object\n",
      "education_num      int64\n",
      "marital_status    object\n",
      "occupation        object\n",
      "relationship      object\n",
      "race              object\n",
      "sex               object\n",
      "capital_gain       int64\n",
      "capital_loss       int64\n",
      "hours_per_week     int64\n",
      "native_country    object\n",
      "income            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "df = pd.read_csv('/Users/reddyharshayadhav/Downloads/Data Trasformation/adult_with_headers (1).csv')\n",
    "\n",
    "# Step 3: Basic exploration\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df.describe(include='all'))\n",
    "print(\"\\nMissing values by column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890720d",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee92c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after imputation:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education_num     0\n",
      "marital_status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital_gain      0\n",
      "capital_loss      0\n",
      "hours_per_week    0\n",
      "native_country    0\n",
      "income            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Handle missing values properly (no errors/warnings)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for col in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        # Only impute with median if column is numeric\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    else:\n",
    "        # Impute categorical with mode\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad0634b",
   "metadata": {},
   "source": [
    "# Scaling Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66ae7add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Scaled data (first 5 rows):\n",
      "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "0  0.030671 -1.063611       1.134739      0.148453      -0.21666   \n",
      "1  0.837109 -1.008707       1.134739     -0.145920      -0.21666   \n",
      "2 -0.042642  0.245079      -0.420060     -0.145920      -0.21666   \n",
      "3  1.057047  0.425801      -1.197459     -0.145920      -0.21666   \n",
      "4 -0.775768  1.408176       1.134739     -0.145920      -0.21666   \n",
      "\n",
      "   hours_per_week  \n",
      "0       -0.035429  \n",
      "1       -2.222153  \n",
      "2       -0.035429  \n",
      "3       -0.035429  \n",
      "4       -0.035429  \n",
      "Min-Max Scaled data (first 5 rows):\n",
      "        age    fnlwgt  education_num  capital_gain  capital_loss  \\\n",
      "0  0.301370  0.044302       0.800000       0.02174           0.0   \n",
      "1  0.452055  0.048238       0.800000       0.00000           0.0   \n",
      "2  0.287671  0.138113       0.533333       0.00000           0.0   \n",
      "3  0.493151  0.151068       0.400000       0.00000           0.0   \n",
      "4  0.150685  0.221488       0.800000       0.00000           0.0   \n",
      "\n",
      "   hours_per_week  \n",
      "0        0.397959  \n",
      "1        0.122449  \n",
      "2        0.397959  \n",
      "3        0.397959  \n",
      "4        0.397959  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Step 5: Select numeric columns\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Standard Scaling\n",
    "scaler_std = StandardScaler()\n",
    "df_standard_scaled = df.copy()\n",
    "df_standard_scaled[num_cols] = scaler_std.fit_transform(df[num_cols])\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler_mm = MinMaxScaler()\n",
    "df_minmax_scaled = df.copy()\n",
    "df_minmax_scaled[num_cols] = scaler_mm.fit_transform(df[num_cols])\n",
    "\n",
    "# Display sample of scaled data\n",
    "print(\"Standard Scaled data (first 5 rows):\")\n",
    "print(df_standard_scaled[num_cols].head())\n",
    "print(\"Min-Max Scaled data (first 5 rows):\")\n",
    "print(df_minmax_scaled[num_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559b3b9",
   "metadata": {},
   "source": [
    "# 2.Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499efdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Data Sample:\n",
      "   age  workclass  fnlwgt  education  education_num  marital_status  \\\n",
      "0   39          7   77516          9             13               4   \n",
      "1   50          6   83311          9             13               2   \n",
      "2   38          4  215646         11              9               0   \n",
      "3   53          4  234721          1              7               2   \n",
      "4   28          4  338409          9             13               2   \n",
      "\n",
      "   occupation  relationship  capital_gain  capital_loss  hours_per_week  \\\n",
      "0           1             1          2174             0              40   \n",
      "1           4             0             0             0              13   \n",
      "2           6             1             0             0              40   \n",
      "3           6             0             0             0              40   \n",
      "4          10             5             0             0              40   \n",
      "\n",
      "   native_country  race_ Asian-Pac-Islander  race_ Black  race_ Other  \\\n",
      "0              39                     False        False        False   \n",
      "1              39                     False        False        False   \n",
      "2              39                     False        False        False   \n",
      "3              39                     False         True        False   \n",
      "4               5                     False         True        False   \n",
      "\n",
      "   race_ White  sex_ Male  income_ >50K  \n",
      "0         True       True         False  \n",
      "1         True       True         False  \n",
      "2         True       True         False  \n",
      "3        False       True         False  \n",
      "4        False      False         False  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Step 6: One-Hot Encoding for categorical features with < 5 categories\n",
    "cat_cols = [col for col in df.select_dtypes(include='object').columns if df[col].nunique() <= 5]\n",
    "df_onehot = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Step 7: Label Encoding for other categorical features\n",
    "le = LabelEncoder()\n",
    "cat_cols_others = [col for col in df.select_dtypes(include='object').columns if col not in cat_cols]\n",
    "df_label = df_onehot.copy()\n",
    "for col in cat_cols_others:\n",
    "    df_label[col] = le.fit_transform(df_label[col])\n",
    "\n",
    "print(\"Encoded Data Sample:\")\n",
    "print(df_label.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad425e9a",
   "metadata": {},
   "source": [
    "Discussion:\n",
    "One-Hot Encoding creates binary columns for each category—best for variables with a few categories and avoids introducing order where it doesn’t exist.\n",
    "Label Encoding assigns numbers to categories, best for tree-based algorithms but can create fake order for linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438cf54f",
   "metadata": {},
   "source": [
    "One-Hot Encoding\n",
    "\n",
    "Pros:\n",
    "\n",
    "No Ordinal Relationship: Prevents introduction of artificial ordinal relationships among categorical values, which is essential for linear models and algorithms sensitive to feature scales.\n",
    "\n",
    "Interpretability: Each category gets its own column, making the encoding easily interpretable.\n",
    "\n",
    "Compatibility: Works well with algorithms that can’t handle categorical variables directly, such as linear regression and logistic regression.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Dimensionality Explosion: Creates a new column for each category, which can lead to a very high-dimensional dataset if a feature has many unique values.\n",
    "\n",
    "Increased Memory and Runtime: The resulting sparse matrices can slow down training and use more memory.\n",
    "\n",
    "Not Suitable for High Cardinality: Not efficient for categorical features with a large number of categories.\n",
    "\n",
    "Label Encoding\n",
    "\n",
    "Pros:\n",
    "\n",
    "Simplicity: Converts categories into numeric codes, which is easy to implement and requires less memory.\n",
    "\n",
    "No Extra Columns: Maintains the original number of columns in the dataset, resulting in efficient storage and computation.\n",
    "\n",
    "Works Well with Tree-Based Models: Algorithms such as decision trees and random forests treat label values as distinct categories, so no ordinal relationship is imposed.\n",
    "\n",
    "Cons:\n",
    "\n",
    "Artificial Ordinal Relationship: May introduce unintended ordinal relationships among categories, which can negatively affect models sensitive to feature value order (e.g., linear models).\n",
    "\n",
    "Misinterpretation Risk: Linear or distance-based algorithms might assume that higher label values have greater importance or relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79671791",
   "metadata": {},
   "source": [
    "# 3.Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd582df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New feature samples:\n",
      "   age age_group  hours_per_week hours_per_week_group\n",
      "0   39     Adult              40            Full-time\n",
      "1   50   Mid-Age              13            Part-time\n",
      "2   38     Adult              40            Full-time\n",
      "3   53   Mid-Age              40            Full-time\n",
      "4   28     Adult              40            Full-time\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Age group feature\n",
    "df['age_group'] = pd.cut(df['age'], bins=[0, 25, 45, 65, 100], labels=['Youth', 'Adult', 'Mid-Age', 'Senior'])\n",
    "\n",
    "# Example 2: Working hours category\n",
    "# Use the correct column name - check your DataFrame's columns!\n",
    "df['hours_per_week_group'] = pd.cut(df['hours_per_week'], bins=[0, 20, 40, 60, np.inf], labels=['Part-time', 'Full-time', 'Overtime', 'Extreme'])\n",
    "\n",
    "print(\"New feature samples:\")\n",
    "print(df[['age', 'age_group', 'hours_per_week', 'hours_per_week_group']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60a965",
   "metadata": {},
   "source": [
    "# Data Transformation (e.g., Log transformation for skewed features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a27aee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income', 'age_group', 'hours_per_week_group']\n",
      "Skewness before transformation: 11.953847687699799\n",
      "Skewness after log transformation: 3.096143524467517\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Check columns and skewness\n",
    "print(df.columns.tolist())  # Check actual column names\n",
    "\n",
    "# Use the correct column name below\n",
    "print(\"Skewness before transformation:\", df['capital_gain'].skew())\n",
    "df['capital_gain_log'] = np.log1p(df['capital_gain'])\n",
    "print(\"Skewness after log transformation:\", df['capital_gain_log'].skew())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76442bbe",
   "metadata": {},
   "source": [
    "Justification for Log Transformation on a Skewed Numerical Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52020955",
   "metadata": {},
   "source": [
    "I applied a log transformation to the capital_gain feature because its distribution was highly skewed, with most individuals having low or zero values and a few with very large gains. Such skewness can hinder model performance and cause instability during training, especially for algorithms sensitive to data distribution. By using a log transformation, I effectively reduced the impact of outliers, compressed the range of values, and made the feature distribution more normal-like. This helps improve the predictive accuracy and stability of machine learning models, ensures that extreme values do not disproportionately influence outcomes, and enhances interpretability. Therefore, the log transformation is an appropriate preprocessing step for numerical features with significant skewness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
